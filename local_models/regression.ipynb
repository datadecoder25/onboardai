{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc347e02-04ab-469e-86e4-23f1e6ea1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66690b1e-a336-40a2-8343-874fc2866a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is Numeric\n",
      "DONE...!!!\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = '/Users/sprosad/Downloads/others/new_dea/onboardai/data/regression/house_price_train.csv'  # Update with your file path\n",
    "df = pd.read_csv(file_path)\n",
    "threshold = 0.5 * len(df)  # 70% of the total number of rows\n",
    "target_col = 'SalePrice'\n",
    "\n",
    "# Drop columns where the number of NaN values is greater than the threshold\n",
    "df_cleaned = df.dropna(thresh=threshold, axis=1)\n",
    "df_cleaned = df_cleaned.dropna(subset=[target_col])\n",
    "\n",
    "# Function to check the percentage of digits in a string\n",
    "def is_digit_heavy_string(value):\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "    digit_count = sum(c.isdigit() for c in value)\n",
    "    return digit_count / len(value) >= 0.9 if len(value) > 0 else False\n",
    "\n",
    "def is_date_string(value):\n",
    "    try:\n",
    "        pd.to_datetime(value)\n",
    "        return True\n",
    "    except (ValueError, TypeError):\n",
    "        return False\n",
    "\n",
    "def custom_is_alphanumeric(value):\n",
    "    if not isinstance(value, str):\n",
    "        return False\n",
    "    \n",
    "    letters = sum(c.isalpha() for c in value)\n",
    "    digits = sum(c.isdigit() for c in value)\n",
    "    \n",
    "    # Apply the rules\n",
    "    if len(value) > 4:\n",
    "        return letters >= 2 and digits >= 2\n",
    "    else:\n",
    "        return letters >= 1 and digits >= 1\n",
    "\n",
    "# Function to tag columns\n",
    "def tag_columns(df, target_col):\n",
    "    column_tags = {'number':[],'string':[],'unknown':[],'date':[],'alphanumeric':[], 'predictor':target_col}\n",
    "    \n",
    "    for column in df.loc[:, df.columns != target_col]:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            column_tags['number'].append(column) \n",
    "        elif pd.api.types.is_string_dtype(df[column]):\n",
    "            # Check if at least 90% of the strings in the column are \"digit-heavy\"\n",
    "            if df[column].apply(is_digit_heavy_string).mean() >= 0.9:\n",
    "                column_tags['number'].append(column) \n",
    "            elif df[column].apply(is_date_string).mean() >= 0.9:\n",
    "                column_tags['date'].append(column)\n",
    "            elif df[column].apply(custom_is_alphanumeric).mean() >= 0.9:\n",
    "                column_tags['alphanumeric'].append(column)\n",
    "            else:\n",
    "                column_tags['string'].append(column) \n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[column]):\n",
    "            column_tags['date'].append(column) \n",
    "        else:\n",
    "            column_tags['unknown'].append(column)\n",
    "    return column_tags\n",
    "\n",
    "# Get tags for the columns\n",
    "column_tags = tag_columns(df_cleaned, target_col)\n",
    "\n",
    "for col in column_tags['number']:\n",
    "    df_cleaned[col] = df_cleaned[col].astype(float)\n",
    "\n",
    "for col in column_tags['string']:\n",
    "    df_cleaned[col] = df_cleaned[col].astype(str)\n",
    "\n",
    "for col in column_tags['date']:\n",
    "    print(\"dat_col\", col)\n",
    "    df_cleaned[col] = pd.to_datetime(df_cleaned[col], format='%Y_%m_%d')\n",
    "\n",
    "if pd.api.types.is_numeric_dtype(df_cleaned[target_col]):\n",
    "    print(\"Target is Numeric\")\n",
    "elif pd.api.types.is_string_dtype(df[column]):\n",
    "    df_cleaned[target_column] = df_cleaned[target_column].replace({'$': '', ',': '','%':''}, regex=True)\n",
    "    if df_cleaned[target_col].astype(str).apply(is_digit_heavy_string).mean() >= 0.9:\n",
    "        print(\"Target is not Numeric... converting it into numeric...\")\n",
    "        df_cleaned[target_col] = df_cleaned[target_col].astype(float)\n",
    "    else:\n",
    "        print(f'{target_col} cant be converted to numeric column')\n",
    "else:\n",
    "    print(f'{target_col} cant be converted to numeric column') \n",
    "\n",
    "today = pd.to_datetime('today')\n",
    "for col in column_tags['date']:\n",
    "    # Calculate the difference in days\n",
    "    df_cleaned['days_difference_'+col] = (today - df_cleaned[col]).dt.days\n",
    "    column_tags['number'].append('days_difference_'+col)\n",
    "    \n",
    "df_cleaned = df_cleaned.drop(column_tags['date'], axis=1)\n",
    "\n",
    "#checking important string columns\n",
    "for col in column_tags['string']:\n",
    "    df_cleaned[col].fillna(df_cleaned[col].mode()[0], inplace=True)\n",
    "# Optionally: Trim whitespace\n",
    "df_cleaned[column_tags['string']] = df_cleaned[column_tags['string']].apply(lambda x: x.str.strip())\n",
    "\n",
    "cardinality = {col: df_cleaned[col].nunique() for col in column_tags['string']}\n",
    "low_cardinality_cols = [col for col in column_tags['string'] if cardinality[col] < 10]\n",
    "df_encoded = pd.get_dummies(df_cleaned, columns=low_cardinality_cols, drop_first=True)\n",
    "\n",
    "new_column_names = [col for col in df_encoded.columns if col.startswith(tuple(low_cardinality_cols))]\n",
    "original_to_new = {col: [new_col for new_col in new_column_names if new_col.startswith(col)] for col in low_cardinality_cols}\n",
    "\n",
    "significant_cat_cols = []\n",
    "for col in new_column_names:\n",
    "    grouped = df_encoded.groupby(col)[target_col].mean()\n",
    "    f_val, p_val = stats.f_oneway(*[group[target_col].values for name, group in df_encoded.groupby(col)])\n",
    "    if p_val<=0.05:\n",
    "       significant_cat_cols.append(col) \n",
    "\n",
    "#checking important numeric columns\n",
    "for col in column_tags['number']:\n",
    "    df_encoded[col].fillna(df_encoded[col].mean(), inplace=True)  # You can also use median or a specific value\n",
    "\n",
    "numeric_cols = column_tags['number'].copy()\n",
    "for col in column_tags['number']:\n",
    "    if 'year' in col.lower():\n",
    "        df_encoded['year_difference_'+col] = df_encoded[col].apply(lambda x: (today.year - x))\n",
    "        numeric_cols.append('year_difference_'+col)\n",
    "        numeric_cols.remove(col)\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = df_encoded[numeric_cols+[target_col]].corr()\n",
    "\n",
    "# Extract the correlation with the target variable\n",
    "target_correlation = correlation_matrix[target_col].abs().sort_values(ascending=False)\n",
    "# Set a correlation threshold\n",
    "correlation_threshold = 0.2\n",
    "\n",
    "# Filter significant columns based on the threshold\n",
    "significant_numeric_columns = target_correlation[target_correlation > correlation_threshold].index.tolist()\n",
    "significant_numeric_columns = [c for c in significant_numeric_columns if c!= target_col]\n",
    "# print(f\"Significant Numeric Columns: {significant_numeric_columns}\")\n",
    "\n",
    "# Prepare X (features) and y (target variable)\n",
    "X = df_encoded[significant_numeric_columns]\n",
    "y = df_encoded[target_col]\n",
    "\n",
    "# Add a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "# Store the significant columns based on p-values from the model summary\n",
    "p_values = model.pvalues\n",
    "\n",
    "# Filter significant predictors (excluding the constant)\n",
    "significant_predictors = p_values[p_values <= 0.05].index.tolist()\n",
    "if 'const' in significant_predictors:\n",
    "    significant_predictors.remove('const')  # Remove the constant term\n",
    "\n",
    "df_final = df_encoded[significant_cat_cols+significant_predictors+[target_col]]\n",
    "\n",
    "print(\"DONE...!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70aa74c0-4405-4271-a09f-627b63f3af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from lightgbm import LGBMRegressor\n",
    "# from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6c18a97-2b18-49ea-9c86-15f55bf4814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = df_final.drop(target_col, axis=1)  # Replace with your target column name\n",
    "y = df_final[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f61d44-4baf-4428-9d2f-13f642157c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b332198-417c-419d-8356-717c1a75aeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_grids = {\n",
    "    \"Linear Regression\": {},\n",
    "    \"Ridge Regression\": {\n",
    "        'alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    \"Lasso Regression\": {\n",
    "        'alpha': [0.1, 1.0, 10.0]\n",
    "    },\n",
    "    \"Decision Tree\": {\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"SVR\": {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'epsilon': [0.1, 0.2, 0.5]\n",
    "    },\n",
    "    \"KNN\": {\n",
    "        'n_neighbors': [3, 5, 7, 9]\n",
    "    },\n",
    "    \"LightGBM\": {\n",
    "        'num_leaves': [31, 50, 100],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [-1, 10, 20]\n",
    "    },\n",
    "    \"XGBoost\": {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 5, 7],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0]\n",
    "    }\n",
    "}\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor(),\n",
    "    \"SVR\": SVR(),\n",
    "    \"KNN\": KNeighborsRegressor(),\n",
    "    # \"LightGBM\": LGBMRegressor(),\n",
    "    # \"XGBoost\": XGBRegressor(eval_metric='rmse')  # Use RMSE for evaluation\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a03db88-92e6-40eb-909d-a97f9c206756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Linear Regression, Best Hyperparameters: {}, Final RMSE: 36152.69201329487\n",
      "Best Model: Ridge Regression, Best Hyperparameters: {'alpha': 1.0}, Final RMSE: 35965.28814310178\n",
      "Best Model: Lasso Regression, Best Hyperparameters: {'alpha': 10.0}, Final RMSE: 36056.875816777385\n",
      "Best Model: Decision Tree, Best Hyperparameters: {'max_depth': 20, 'min_samples_split': 10}, Final RMSE: 48718.87620786183\n",
      "Best Model: Random Forest, Best Hyperparameters: {'max_depth': 30, 'min_samples_split': 2, 'n_estimators': 200}, Final RMSE: 34866.87451213228\n",
      "Best Model: SVR, Best Hyperparameters: {'C': 10, 'epsilon': 0.1}, Final RMSE: 78915.45563966435\n",
      "Best Model: KNN, Best Hyperparameters: {'n_neighbors': 9}, Final RMSE: 64013.80168016677\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "best_rmse = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    param_grid = hyperparameter_grids[model_name]\n",
    "\n",
    "    grid_search = GridSearchCV(model, param_grid, scoring='neg_mean_squared_error', cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    predictions = best_model.predict(X_test)\n",
    "    final_rmse = np.sqrt(-grid_search.best_score_)  # Convert negative MSE to RMSE\n",
    "\n",
    "    best_models[model_name] = best_model\n",
    "    best_rmse[model_name] = final_rmse\n",
    "    print(f\"Best Model: {model_name}, Best Hyperparameters: {grid_search.best_params_}, Final RMSE: {final_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15eb162e-7d4c-4b8c-b124-635f17d0e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of RMSE across models:\n",
      "Linear Regression: RMSE = 36152.69201329487\n",
      "Ridge Regression: RMSE = 35965.28814310178\n",
      "Lasso Regression: RMSE = 36056.875816777385\n",
      "Decision Tree: RMSE = 48718.87620786183\n",
      "Random Forest: RMSE = 34866.87451213228\n",
      "SVR: RMSE = 78915.45563966435\n",
      "KNN: RMSE = 64013.80168016677\n",
      "Best Overall Model: Random Forest with RMSE: 34866.87451213228\n"
     ]
    }
   ],
   "source": [
    "# Identify the best model based on RMSE\n",
    "best_overall_model_name = min(best_rmse, key=best_rmse.get)\n",
    "best_overall_rmse = best_rmse[best_overall_model_name]\n",
    "\n",
    "print(\"Comparison of RMSE across models:\")\n",
    "for model, rmse in best_rmse.items():\n",
    "    print(f\"{model}: RMSE = {rmse}\")\n",
    "\n",
    "print(f\"Best Overall Model: {best_overall_model_name} with RMSE: {best_overall_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cabd8-b5ed-4a45-9e48-89baea29174f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
